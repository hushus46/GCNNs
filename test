import torch
import torch.nn as nn
import torch.optim as optim

# tiny dummy model
model = nn.Sequential(
    nn.Conv2d(1, 8, kernel_size=3, padding=1),
    nn.ReLU(),
    nn.Flatten(),
    nn.Linear(8 * 28 * 28, 10)
)

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

x = torch.randn(32, 1, 28, 28, device=device)  # fake batch
y = torch.randint(0, 10, (32,), device=device)

opt = optim.Adam(model.parameters())
loss_fn = nn.CrossEntropyLoss()

for step in range(3):
    opt.zero_grad()
    logits = model(x)
    loss = loss_fn(logits, y)
    loss.backward()
    opt.step()
    print(f"step {step}, loss = {loss.item():.4f}")