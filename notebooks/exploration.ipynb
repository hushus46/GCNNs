{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ddaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# !pip install torchvision\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# !pip install torchmetrics\n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"dataset/\", download=True, train=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=\"dataset/\", download=True, train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec42f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    image, label = train_dataset[i]\n",
    "    print(f\"Sample {i}: Image shape = {image.shape}, Label = {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        # Read magic number, number of images, rows, and columns\n",
    "        magic = int.from_bytes(f.read(4), 'big')\n",
    "        num_images = int.from_bytes(f.read(4), 'big')\n",
    "        num_rows = int.from_bytes(f.read(4), 'big')\n",
    "        num_cols = int.from_bytes(f.read(4), 'big')\n",
    "\n",
    "        # Read the image data\n",
    "        image_data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = image_data.reshape(num_images, num_rows, num_cols)\n",
    "    return images\n",
    "\n",
    "train_images = load_mnist_images('dataset/MNIST/raw/train-images-idx3-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f82d9e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplt\u001b[49m.imshow(train_images[\u001b[32m2\u001b[39m], cmap=\u001b[33m'\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mFirst MNIST Image\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m plt.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(train_images[2], cmap='gray')\n",
    "plt.title(\"First MNIST Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 10, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(50):\n",
    "    axes[i].imshow(train_images[i], cmap='gray')\n",
    "    axes[i].set_title(f\"Image {i}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "   npimg = img.numpy()\n",
    "   plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "   plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "labels\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "   def __init__(self, in_channels, num_classes):\n",
    "\n",
    "       \"\"\"\n",
    "       Building blocks of convolutional neural network.\n",
    "\n",
    "       Parameters:\n",
    "           * in_channels: Number of channels in the input image (for grayscale images, 1)\n",
    "           * num_classes: Number of classes to predict. In our problem, 10 (i.e digits from  0 to 9).\n",
    "       \"\"\"\n",
    "       super(CNN, self).__init__()\n",
    "\n",
    "       # 1st convolutional layer\n",
    "       self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, padding=1)\n",
    "       # Max pooling layer\n",
    "       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "       # 2nd convolutional layer\n",
    "       self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "       # Fully connected layer\n",
    "       self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "   def forward(self, x):\n",
    "       \"\"\"\n",
    "       Define the forward pass of the neural network.\n",
    "\n",
    "       Parameters:\n",
    "           x: Input tensor.\n",
    "\n",
    "       Returns:\n",
    "           torch.Tensor\n",
    "               The output tensor after passing through the network.\n",
    "       \"\"\"\n",
    "       x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\n",
    "       x = self.pool(x)           # Apply max pooling\n",
    "       x = F.relu(self.conv2(x))  # Apply second convolution and ReLU activation\n",
    "       x = self.pool(x)           # Apply max pooling\n",
    "       x = x.reshape(x.shape[0], -1)  # Flatten the tensor\n",
    "       x = self.fc1(x)            # Apply fully connected layer\n",
    "       return x\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = CNN(in_channels=1, num_classes=10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    " # Iterate over training batches\n",
    "   print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "   for batch_index, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "       data = data.to(device)\n",
    "       targets = targets.to(device)\n",
    "       scores = model(data)\n",
    "       loss = criterion(scores, targets)\n",
    "       optimizer.zero_grad()\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "print(next(model.parameters()).device, data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n",
      "Model in eval mode? True\n",
      "Test batch shape: torch.Size([60, 1, 28, 28])\n",
      "Predictions shape: torch.Size([60])\n",
      "Sample predictions: tensor([9, 3, 1, 1, 9, 7, 5, 9, 1, 0, 4, 5, 3, 7, 3, 2, 8, 4, 3, 7, 5, 7, 0, 2,\n",
      "        5, 6, 1, 4, 0, 8, 7, 0, 3, 1, 8, 8, 6, 5, 3, 8, 4, 4, 6, 2, 1, 5, 5, 7,\n",
      "        6, 1, 9, 1, 7, 5, 8, 9, 5, 7, 3, 1], device='cuda:0')\n",
      "Sample labels: tensor([9, 3, 1, 1, 9, 7, 5, 4, 1, 0, 4, 5, 3, 7, 3, 2, 8, 4, 3, 7, 5, 7, 0, 2,\n",
      "        5, 6, 1, 4, 0, 8, 7, 0, 3, 1, 8, 8, 6, 5, 3, 8, 4, 4, 6, 2, 1, 6, 5, 7,\n",
      "        6, 1, 9, 1, 7, 5, 8, 9, 5, 7, 3, 1], device='cuda:0')\n",
      "Sample accuracy on batch: 0.9666666984558105\n"
     ]
    }
   ],
   "source": [
    "# Print final model device and a test forward pass\n",
    "print(\"Model device:\", next(model.parameters()).device)\n",
    "print(\"Model in eval mode?\", not model.training)\n",
    "\n",
    "# Check one batch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch, test_labels = next(iter(test_loader))\n",
    "    test_batch = test_batch.to(device)\n",
    "    test_labels = test_labels.to(device)\n",
    "    out = model(test_batch)\n",
    "    preds = out.argmax(dim=1)\n",
    "    print(\"Test batch shape:\", test_batch.shape)\n",
    "    print(\"Predictions shape:\", preds.shape)\n",
    "    print(\"Sample predictions:\", preds[:60])\n",
    "    print(\"Sample labels:\", test_labels[:60])\n",
    "    print(\"Sample accuracy on batch:\", (preds == test_labels).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88598a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up of multiclass accuracy, precision, and recall metrics\n",
    "acc = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "precision = Precision(task=\"multiclass\", num_classes=10).to(device)\n",
    "recall = Recall(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "model.eval()\n",
    "acc.reset(); precision.reset(); recall.reset()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        acc.update(preds, labels)\n",
    "        precision.update(preds, labels)\n",
    "        recall.update(preds, labels)\n",
    "\n",
    "test_accuracy = acc.compute()\n",
    "test_precision = precision.compute()\n",
    "test_recall = recall.compute()\n",
    "print(test_accuracy, test_precision, test_recall)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml312-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
